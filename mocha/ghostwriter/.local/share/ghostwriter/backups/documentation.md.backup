---
title: "*rockscale* — An Algorithmic Video Upscaler with ROCm"
subtitle: "**SIT315 Task M4.T1D: Project Documentation**\\vspace{2em}"
author: "Keo Ponleou Sok"
date: "\\today"
titlepage: true
titlepage-rule-height: 1.5

output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    cover: true
    number_sections: true
    keep_tex: true

header-includes:
  - \usepackage[dvipsnames]{xcolor}
  - \usepackage{graphicx}
  - \usepackage{float}
  - \floatplacement{figure}{H}
  - \usepackage{listings}
  - \usepackage{fancyhdr}
  - \usepackage[en-AU]{datetime2}
  
  - \setcounter{secnumdepth}{3}
  
  - \lstset{
      basicstyle=\ttfamily\small,
      breaklines=true,
      columns=flexible,
      showstringspaces=false,
      keywordstyle=\color{blue}\bfseries,
      commentstyle=\color{teal},
      stringstyle=\color{brown},
      identifierstyle=\color{black}
    } 
    
  - \AtBeginDocument{\hypersetup{linkcolor=black,urlcolor=black,citecolor=black}}
  
  - \usepackage{titling} 
  - \renewcommand\maketitlehooka{\vspace*{-2in}\null\vfill\thispagestyle{empty}}
  - \renewcommand\maketitlehookd{\vfill\null}
  
  - \usepackage{tocloft}
  - \renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
  - \renewcommand{\cftsubsecleader}{\cftdotfill{\cftdotsep}}
  - \renewcommand{\cftsubsubsecleader}{\cftdotfill{\cftdotsep}}
  
  - \fancypagestyle{plain}{\fancyhf{}\renewcommand{\headrulewidth}{0pt}} 
...

<div style="page-break-after: always;">\pagebreak</div>

\tableofcontents

<div style="page-break-after: always;">\pagebreak</div>

# Introduction

*rockscale* is a CLI program built with HIP to optimise GPU performance to upscale video using interpolation algorithms. The program uses FFmpeg to decode videos into individual frames, and each frames are copied into the device memory, where HIP interpolation kernels are ran to interpolate pixels within the frame. The program offers 3 different interpolation algorithms—bilinear, bicubic and lanczos. After interpolation, each frames are copied back to host memory, and are passed into the encoder to output a new, upscaled video. Both software and hardware encoder options are provided. Tested video configurations include `mp4`, `mkv`, and `mov` containers, with `h264` and `h265/hevc` codec. Other video file configurations may work, but have not been tested. Though HIP theoretically should be able to compile the program to utilise CUDA platform, only ROCm has been tested due to accessibility. Additionally, only `vaapi` hardware encoders have been tested.

# Architecture

The architecture of the program is a multithreaded producer-processor-consumer model, with each role capable of running in multiple threads to share workload. The producer in this program is the decoder, decoding the video packets into individual frames, in which thread workers are organised by the FFmpeg library itself. Frame are then passed into a bounded queue, in which the processor can consume in order to upscale through interpolation.

The processors are responsible for taking frames from the decoder's queue, in which the frames are then processed through interpolation. This interpolation processing uses HIP kernel to take advantage of GPU parallel computing. Each interpolation algorithm—bilinear, bicubic, and lanczos—have its own series of kernel functions in order to process the frames. When multiple threads are assigned to the processor role, each thread will consume its own frame from the decoder buffer, and pass kernel functions into its own kernel streams, allowing ROCm (or the parallel computing platform) to optimise multiple streams processing, and ensuring optimal device utilisation. Each processing threads then pass the upscaled frame into the encoder's bounded priority queue.

The consumer runs FFmpeg's encoder, which takes frames from its priority queue, and packages them into a new file's streams, and closes the file once queue is empty. Additionally, if a hardware encoder is chosen for the consumer, the processors have an extra step to copy the frame data into a hardware frame in the device's memory before appending it in the encoder's priority queue. The encoder's priority queue works differently from a traditional FIFO queue. Since encoding frames into packages requires ordering the frames by its `pts` value, all frames passed into the priority queue are ordered by ascending `pts` and the encoder consumes each frame from the buffer in that order.

## Architectural Limitations

Due to the requirements of a bounded encoder buffer, with strict priority of frames' `pts` order during encoding, it poses a limitation when used with multiple processing threads. Since the decoder produces frames also within the ascending `pts` order, a processor thread pick frames from the decoder queue in that order as well, and ideally, append the processed frame in the encoder's queue before picking up the next frame. If this was the case, then a priority queue for the encoder queue would not be necessary as it is guaranteed that the order of frames is determined by the decoder's output. The problem arises when multiple processor threads will each take its own frames, process them, and append them to the encoder queue in a non-deterministic order. In this case, it is possible, and rather common, that the frames inside the encoder queue is not in the same order as the output from the decoder.

Hence, a priority queue is required to accommodate the fact that the frames inputted in the queue is not in the correct order. It should be realised that a priority queue would only function when the frames are picked when there is more than one frame in the queue, so that the queue will compare the `pts` of the different frames inside the queue and output the smallest `pts` available in the queue. In the ideal scenario the encoder's queue should be unbounded, and frames from the queue should be consumed only when all frames are appended. Only this way would we guarantee that the frames consumed by the encoder is in perfect `pts` order.